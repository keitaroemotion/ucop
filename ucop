#!/usr/bin/env python3

import re
import ssl
import sys
import urllib.request

options  = [x for x in sys.argv if re.search(r'^-',     x)]
args     = [x for x in sys.argv if re.search(r'^[^-]+', x)]
keywords = [x for x in args     if (not re.search(r'http[s]*', x)) and (not x == __file__)]
query    = ".*".join(keywords)

print(keywords)

if ("-h" in options) or ("help" in options):
    print("")
    print("ucop --[tag] [http(s)://...]             ... enlist and copy the content of the " + \
                                                       "web on clipboard.")
    print("ucop --[tag] [http(s)://...] [key words] ... copy the filtered content on clipboard.")
    print("ucop -h                                  ... show help menu")
    print("")
    sys.exit()

print("ops: %s, args: %s" % (options, args))

if len(args) < 2:
    print("\nyou need argument.\n")
    sys.exit()

urls = [x for x in args if re.search(r'http[s]*://', x)]

if len(urls) == 0:
    print("\nyou need urls (http[s]://)\n")
    sys.exit()

url = urls[0]

print("[url: %s]\n" % url)
page = urllib.request.urlopen(url, context=ssl.SSLContext())

def extract_content(page, tag, query):
    for x in filter(
                 lambda a: (a != "") and re.search(query, a),
                 map(
                     lambda a: a
                                   .split(">")[1]
                                   .split("<")[0]
                                   .replace("\\r", "")
                                   .replace("\\n", "")
                                   .strip()
                                   ,
                     re.findall(r'<%s\s*[^<>]*>[^<>]+</%s>' % (tag, tag), str(page.read()))
                 )
              ):
        print(x.replace('\n', ""))

for option in filter(lambda x: x.startswith("--"), options):
    tag = option.replace("--", "")
    extract_content(page, tag, query)
